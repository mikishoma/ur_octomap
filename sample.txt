
nvarguscamerasrc / filesrc
   ↓
nvvideoconvert
   ↓
nvstreammux
   ↓
nvinfer（解析）
   ↓
nvtracker（オプション）
   ↓
nvvideoconvert
   ↓
nvdsosd（バウンディングボックス描画など）
   ↓
nvvideoconvert
   ↓
capsfilter (例: video/x-raw(memory:NVMM), format=I420)
   ↓
omxh264enc（またはnvv4l2h264enc）
   ↓
h264parse
   ↓
qtmux
   ↓
filesink location=output.mp4








import gi
gi.require_version('Gst', '1.0')
gi.require_version('GstBase', '1.0')
from gi.repository import Gst, GLib

Gst.init(None)

pipeline = Gst.Pipeline()

# ... 他のエレメント設定 ...

# 例: 出力部分の構成
conv_post_osd = Gst.ElementFactory.make("nvvideoconvert", "conv_post_osd")
capsfilter = Gst.ElementFactory.make("capsfilter", "capsfilter")
capsfilter.set_property("caps", Gst.Caps.from_string("video/x-raw(memory:NVMM), format=I420"))

encoder = Gst.ElementFactory.make("nvv4l2h264enc", "h264_encoder")
encoder.set_property("bitrate", 4000000)

h264parse = Gst.ElementFactory.make("h264parse", "h264_parse")
qtmux = Gst.ElementFactory.make("qtmux", "qt_mux")

sink = Gst.ElementFactory.make("filesink", "file_sink")
sink.set_property("location", "output.mp4")

# エレメントをパイプラインに追加しリンク
for elem in [conv_post_osd, capsfilter, encoder, h264parse, qtmux, sink]:
    pipeline.add(elem)

conv_post_osd.link(capsfilter)
capsfilter.link(encoder)
encoder.link(h264parse)
h264parse.link(qtmux)
qtmux.link(sink)




import sys
import gi
import pyds
from gi.repository import Gst, GLib

gi.require_version('Gst', '1.0')
Gst.init(None)

# パイプラインの初期化
pipeline = Gst.Pipeline()

# ソースエレメントの作成
source = Gst.ElementFactory.make("v4l2src", "video-source")
source.set_property("device", "/dev/video0")

# フォーマット変換エレメントの作成
caps_filter = Gst.ElementFactory.make("capsfilter", "caps-filter")
caps = Gst.Caps.from_string("video/x-raw,format=YUY2,width=640,height=480")
caps_filter.set_property("caps", caps)

# nvstreammuxの作成
mux = Gst.ElementFactory.make("nvstreammux", "nv-muxer")
mux.set_property("batch-size", 1)
mux.set_property("width", 640)
mux.set_property("height", 480)
mux.set_property("live-source", True)

# nvinferの作成（解析用）
pgie = Gst.ElementFactory.make("nvinfer", "primary-nvinference-engine")
pgie.set_property("config-file-path", "dstest1_pgie_config.txt")

# OSDエレメントの作成
osd = Gst.ElementFactory.make("nvdsosd", "nv-onscreendisplay")

# エンコードエレメントの作成
encoder = Gst.ElementFactory.make("nvv4l2h264enc", "video-encoder")
encoder.set_property("bitrate", 4000000)

# パーサーの作成
parser = Gst.ElementFactory.make("h264parse", "h264-parser")

# MP4マルチプレクサの作成
muxer = Gst.ElementFactory.make("mp4mux", "mp4-muxer")

# ファイルシンクの作成
sink = Gst.ElementFactory.make("filesink", "file-sink")
sink.set_property("location", "output.mp4")
sink.set_property("sync", False)

# エレメントをパイプラインに追加
for element in [source, caps_filter, mux, pgie, osd, encoder, parser, muxer, sink]:
    if not element:
        sys.stderr.write(f"Unable to create element {element.get_name()}\n")
        exit(-1)
    pipeline.add(element)

# エレメントをリンク
source.link(caps_filter)
caps_filter.link(mux)
mux.link(pgie)
pgie.link(osd)
osd.link(encoder)
encoder.link(parser)
parser.link(muxer)
muxer.link(sink)

# パイプラインの再生
pipeline.set_state(Gst.State.PLAYING)

# イベントループの開始
loop = GLib.MainLoop()
try:
    loop.run()
except:
    pass

# パイプラインの停止
pipeline.set_state(Gst.State.NULL)
